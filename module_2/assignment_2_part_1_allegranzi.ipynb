{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors. Edited by Eric Braude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 Part 1 - Alessandro Allegranzi\n"
      ],
      "metadata": {
        "id": "zXfyRk78US4v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for beginners, edited by Eric Braude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "I recommend runniing on Colab.\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/beginner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/beginner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "This uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
        "\n",
        "1. Build a neural network that classifies images.\n",
        "2. Train this neural network.\n",
        "3. And, finally, evaluate the accuracy of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*. (I did not need to do this- EB)\n",
        "2. To run all the notebook code cells (i.e., not just one at a time): Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "AS NEEDED ... Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Visualize: https://www.tensorflow.org/datasets/catalog/mnist Convert the samples from integers to floating-point numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FP5258xjs-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51bfa7e8-9937-47f0-cd97-bebb44bb7768"
      },
      "source": [
        "# INTENT: Load the IMDB review data.\n",
        "\n",
        "mnist = tf.keras.datasets.mnist # one of a handful of data sets known to Keras/TensorFlow\n",
        "# mnist.load_data() produces a pair of input/output tensors for training\n",
        "# and one for testing.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"===========y_train===========\")\n",
        "print(tf.shape(y_train))\n",
        "print(y_train)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # scale down input\n",
        "print(\"===========x_train===========\")\n",
        "print(tf.shape(x_train))\n",
        "print(\"===========x_train element 0 (28 rows of 28 gray values)===========\")\n",
        "print(x_train[0])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========y_train===========\n",
            "tf.Tensor([60000], shape=(1,), dtype=int32)\n",
            "[5 0 4 ... 5 6 8]\n",
            "===========x_train===========\n",
            "tf.Tensor([60000    28    28], shape=(3,), dtype=int32)\n",
            "===========x_train element 0 (28 rows of 28 gray values)===========\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
            "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
            "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
            "  0.99215686 0.35294118 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.54509804\n",
            "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313725\n",
            "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
            "  0.09803922 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            "  0.58823529 0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
            "  0.99215686 0.73333333 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.97647059\n",
            "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
            "  0.98039216 0.71372549 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.44705882\n",
            "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
            "  0.30588235 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.21568627 0.6745098\n",
            "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "  0.52156863 0.04313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.53333333 0.99215686\n",
            "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras.Sequential` model (object) by stacking layers.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "model = tf.keras.models.Sequential([ # layer format for the neural net\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # each pixel (grayscale value) mapped to one of 784 nodes\n",
        "  # tf.keras.layers.Dense(25, activation='sigmoid'), # fully connected to hidden layer with sigmoid, lowered neurons to 25\n",
        "  tf.keras.layers.Dense(150, activation='relu'), # Increased neurons up to 150 and used relu to improve model.\n",
        "  # Dropout layer randomly sets its input units to 0 at 20% rate at each training step\n",
        "  # The other inputs are scaled up by 1/0.8 so sum over all inputs is unchanged\n",
        "  # Illustrative figure: http://laid.delanover.com/wp-content/uploads/2018/02/dropout.png\n",
        "  # (see https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10) # e.g., output #7 expresses degree to which the input is a 7\n",
        "])\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "For each example the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" or \"[log-odds](https://developers.google.com/machine-learning/glossary#log-odds)\" scores, one for each class.\n",
        "\n",
        "In other words, a tensor where the highest value indicates the most likely output.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Logit\n",
        "\n",
        "model() acts like a function, returning the neural net object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeOrNdnkEEcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a798bee-298d-4647-df00-d93c14e91e22"
      },
      "source": [
        "print(\"===========first element of x_train (29 rows)===========\")\n",
        "print(x_train[:1])\n",
        "\n",
        "predictions = model(x_train[:1]).numpy() # numpy() converts the tensor output\n",
        "print(\"===========untrained output of first training set input===========\")\n",
        "predictions"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========first element of x_train (29 rows)===========\n",
            "[[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
            "   0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            "   0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "   0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
            "   0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            "   0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
            "   0.99215686 0.35294118 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.54509804\n",
            "   0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.04313725\n",
            "   0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
            "   0.09803922 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            "   0.58823529 0.10588235 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
            "   0.99215686 0.73333333 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.97647059\n",
            "   0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            "   0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
            "   0.98039216 0.71372549 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.09411765 0.44705882\n",
            "   0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
            "   0.30588235 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.21568627 0.6745098\n",
            "   0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "   0.52156863 0.04313725 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.53333333 0.99215686\n",
            "   0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n",
            "===========untrained output of first training set input===========\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.09860671, -0.32874662,  0.4740216 , -0.24705184,  0.22679141,\n",
              "         0.07655796, -0.20971206,  0.08804052, -0.2761206 , -0.26757535]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgjhDQGcIniO"
      },
      "source": [
        "The `tf.nn.softmax` function converts these logits to \"probabilities\" for each class (summing to 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSRnQ0WI5eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db0f471-8e2d-4ff9-f483-c59fc91e1752"
      },
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09270121, 0.07364392, 0.1643519 , 0.07991283, 0.1283524 ,\n",
              "        0.11044814, 0.08295316, 0.11172369, 0.07762329, 0.07828946]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he5u_okAYS4a"
      },
      "source": [
        "Note: It is possible to bake this `tf.nn.softmax` in as the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to\n",
        "provide an exact and numerically stable loss calculation for all models when using a softmax output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "The `losses.SparseCategoricalCrossentropy` loss takes a vector of logits and a `True` index and returns a scalar loss for each example.\n",
        "\n",
        "sparse categorical crossentropy\n",
        "(https://docs.google.com/document/d/16v7AIXuwAwdOZxorwSDXKRGzJA8jUYAR_D-QJTxEiyA/edit?usp=sharing)\n",
        "We give it a short name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSkzdv8MD0tT"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfR4MsSDU880"
      },
      "source": [
        "This loss is equal to the negative log probability of the true class:\n",
        "It is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to `-tf.math.log(1/10) ~= 2.3`.\n",
        "\n",
        "Recall that y_train is the target (desired output) tensor. We select the first element."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJWqEVrrJ7ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e54dd44-4aa9-4cc1-b078-456726c84c3e"
      },
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2032092"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9foNKHzTD2Vo"
      },
      "source": [
        "# Put together the NN with training process, loss, and means of evaluation.\n",
        "# 'accuracy' = proportion of correct predictions vs. total number of cases\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "The `Model.fit` method adjusts the model's parameters to minimize the loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7suUbJXVLqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d2b20b-4615-45fa-c82f-d84ac60dad69"
      },
      "source": [
        "# # Calculate half the number of samples.\n",
        "# num_samples = int(0.5 * len(x_train))\n",
        "\n",
        "# # Select a subset of half the original data\n",
        "# x_train_subset = x_train[:num_samples]\n",
        "# y_train_subset = y_train[:num_samples]\n",
        "\n",
        "# Train it with 8 epochs and full data\n",
        "model.fit(x_train, y_train, epochs=8)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2805 - accuracy: 0.9194\n",
            "Epoch 2/8\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1326 - accuracy: 0.9606\n",
            "Epoch 3/8\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0980 - accuracy: 0.9702\n",
            "Epoch 4/8\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0800 - accuracy: 0.9746\n",
            "Epoch 5/8\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0676 - accuracy: 0.9790\n",
            "Epoch 6/8\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0593 - accuracy: 0.9810\n",
            "Epoch 7/8\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0527 - accuracy: 0.9834\n",
            "Epoch 8/8\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0447 - accuracy: 0.9856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa67c625450>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "The `Model.evaluate` method checks the models performance, usually on a \"[Validation-set](https://developers.google.com/machine-learning/glossary#validation-set)\" or \"[Test-set](https://developers.google.com/machine-learning/glossary#test-set)\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7dTAzgHDUh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b70bf2-2492-4243-d7d7-0507a39884ca"
      },
      "source": [
        "# Accuracy = fraction of correct test pairs\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0676 - accuracy: 0.9803 - 803ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06763662397861481, 0.9803000092506409]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnqOZtUp1YR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9c73c6-6462-4075-8b7b-7839ea912bf9"
      },
      "source": [
        "probability_model(x_test[:5])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[4.69346784e-10, 8.12970871e-12, 5.15578620e-07, 2.08178449e-06,\n",
              "        2.42672167e-11, 1.31815519e-08, 1.05826252e-16, 9.99995947e-01,\n",
              "        4.25251917e-11, 1.59513081e-06],\n",
              "       [6.53053278e-10, 8.27759959e-06, 9.99990582e-01, 1.03168338e-06,\n",
              "        8.59171823e-19, 2.12026894e-08, 2.38588385e-08, 6.55862474e-12,\n",
              "        8.24071336e-08, 6.91888857e-16],\n",
              "       [2.90136626e-08, 9.99329090e-01, 1.91368072e-05, 9.31339230e-07,\n",
              "        2.65980407e-06, 4.85643966e-07, 6.52986182e-06, 6.16225065e-04,\n",
              "        2.48050983e-05, 9.69984555e-08],\n",
              "       [9.99868751e-01, 2.38761060e-11, 2.16848633e-07, 4.92103247e-10,\n",
              "        6.76955665e-08, 6.91781068e-08, 1.24643280e-04, 5.71941291e-06,\n",
              "        7.70536523e-10, 4.00168119e-07],\n",
              "       [5.44614220e-09, 2.61326599e-10, 1.82564435e-07, 3.79575760e-10,\n",
              "        9.98593509e-01, 6.15089935e-09, 1.05871194e-07, 5.17831495e-06,\n",
              "        2.88057089e-09, 1.40100555e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ]
}